{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase C: IA Générative et Agents\n",
                "\n",
                "## Objectifs\n",
                "1. **Zero-shot / Few-shot Classification** avec un LLM\n",
                "2. **Aspect-Based Sentiment Analysis (ABSA)** avec LangChain\n",
                "\n",
                "Ce notebook utilise des modèles de langage pour analyser les avis sans entraînement spécifique."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Load sample of reviews\n",
                "df = pd.read_parquet(\"../Data/prepared_reviews.parquet\")\n",
                "# Small sample for LLM testing (API calls are expensive/slow)\n",
                "sample = df.sample(20, random_state=42)\n",
                "print(f\"Testing on {len(sample)} reviews\")\n",
                "sample.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Zero-shot Classification avec Transformers (Local)\n",
                "\n",
                "Utilisation de `pipeline` de HuggingFace pour la classification zero-shot."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "# Zero-shot classification pipeline\n",
                "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=-1)\n",
                "\n",
                "candidate_labels = [\"positive\", \"negative\", \"neutral\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on sample\n",
                "results = []\n",
                "for idx, row in tqdm(sample.iterrows(), total=len(sample), desc=\"Zero-shot\"):\n",
                "    text = row['text'][:512]  # Truncate for speed\n",
                "    result = classifier(text, candidate_labels)\n",
                "    predicted = result['labels'][0]\n",
                "    results.append({\n",
                "        'text': text[:100] + '...',\n",
                "        'actual': row['polarity'],\n",
                "        'predicted': predicted,\n",
                "        'confidence': result['scores'][0]\n",
                "    })\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "print(results_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Accuracy\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "accuracy = accuracy_score(results_df['actual'], results_df['predicted'])\n",
                "print(f\"Zero-shot Accuracy: {accuracy:.4f}\")\n",
                "print(classification_report(results_df['actual'], results_df['predicted']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Few-shot Classification (avec exemples)\n",
                "\n",
                "On donne quelques exemples au modèle pour améliorer ses prédictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Few-shot examples\n",
                "few_shot_examples = \"\"\"\n",
                "Examples:\n",
                "- \"The food was amazing and service was great!\" -> positive\n",
                "- \"Terrible experience. Never coming back.\" -> negative\n",
                "- \"It was okay, nothing special.\" -> neutral\n",
                "\n",
                "Now classify this review:\n",
                "\"\"\"\n",
                "\n",
                "def few_shot_classify(text):\n",
                "    prompt = few_shot_examples + f'\"{text[:200]}\" -> '\n",
                "    result = classifier(prompt, candidate_labels)\n",
                "    return result['labels'][0], result['scores'][0]\n",
                "\n",
                "# Test\n",
                "test_text = sample.iloc[0]['text']\n",
                "pred, conf = few_shot_classify(test_text)\n",
                "print(f\"Prediction: {pred} (confidence: {conf:.2f})\")\n",
                "print(f\"Actual: {sample.iloc[0]['polarity']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Aspect-Based Sentiment Analysis (ABSA)\n",
                "\n",
                "Extraction des aspects et leur sentiment associé."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple ABSA using keyword detection + sentiment\n",
                "ASPECTS = ['food', 'service', 'price', 'atmosphere', 'location', 'cleanliness', 'staff', 'quality']\n",
                "\n",
                "sentiment_classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
                "\n",
                "def extract_aspects(text):\n",
                "    text_lower = text.lower()\n",
                "    found_aspects = []\n",
                "    \n",
                "    # Split into sentences\n",
                "    sentences = text.split('.')\n",
                "    \n",
                "    for aspect in ASPECTS:\n",
                "        for sentence in sentences:\n",
                "            if aspect in sentence.lower():\n",
                "                sentiment = sentiment_classifier(sentence[:512])[0]\n",
                "                found_aspects.append({\n",
                "                    'aspect': aspect,\n",
                "                    'sentiment': sentiment['label'],\n",
                "                    'confidence': sentiment['score'],\n",
                "                    'context': sentence.strip()[:100]\n",
                "                })\n",
                "                break  # One mention per aspect\n",
                "    \n",
                "    return found_aspects"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test ABSA on samples\n",
                "print(\"=== Aspect-Based Sentiment Analysis ===\")\n",
                "for idx in range(min(5, len(sample))):\n",
                "    text = sample.iloc[idx]['text']\n",
                "    print(f\"\\n--- Review {idx+1} (Stars: {sample.iloc[idx]['stars']}) ---\")\n",
                "    print(f\"Text: {text[:200]}...\")\n",
                "    \n",
                "    aspects = extract_aspects(text)\n",
                "    if aspects:\n",
                "        print(\"Aspects found:\")\n",
                "        for a in aspects:\n",
                "            print(f\"  - {a['aspect'].upper()}: {a['sentiment']} ({a['confidence']:.2f})\")\n",
                "    else:\n",
                "        print(\"No specific aspects found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Structured Output (JSON)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_review(text):\n",
                "    \"\"\"Complete analysis of a review with structured output.\"\"\"\n",
                "    # Overall sentiment\n",
                "    overall = classifier(text[:512], candidate_labels)\n",
                "    \n",
                "    # Aspects\n",
                "    aspects = extract_aspects(text)\n",
                "    \n",
                "    return {\n",
                "        'overall_sentiment': overall['labels'][0],\n",
                "        'overall_confidence': float(overall['scores'][0]),\n",
                "        'aspects': aspects,\n",
                "        'text_preview': text[:200]\n",
                "    }\n",
                "\n",
                "# Demo\n",
                "demo_review = sample.iloc[0]['text']\n",
                "analysis = analyze_review(demo_review)\n",
                "print(json.dumps(analysis, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Summary & Comparison with Phase B"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=== GenAI Phase Summary ===\")\n",
                "print(f\"Zero-shot Accuracy (on {len(sample)} samples): {accuracy:.2%}\")\n",
                "print(\"\\nAdvantages of GenAI approach:\")\n",
                "print(\"  - No training required\")\n",
                "print(\"  - Can extract aspects and explanations\")\n",
                "print(\"  - Flexible to new domains\")\n",
                "print(\"\\nDisadvantages:\")\n",
                "print(\"  - Slower inference\")\n",
                "print(\"  - May be less accurate than fine-tuned models\")\n",
                "print(\"  - Requires larger models for best results\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}